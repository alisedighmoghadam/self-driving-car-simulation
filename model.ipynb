{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd276b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "Y_START,Y_END=60,135\n",
    "IMG_SIZE=(200,66)\n",
    "BATCH = 32\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805e1d0",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(\n",
    "    image, \n",
    "    steering_angle, \n",
    "    flip_prob=0.5, \n",
    "    brightness_prob=0.5, \n",
    "    zoom_prob=0.5, \n",
    "    pan_prob=0.5, \n",
    "    rotate_prob=0.5,\n",
    "    max_brightness_delta=0.25,   # ~±25% brightness\n",
    "    max_zoom=0.2,                # up to 20% zoom-in\n",
    "    max_translation=0.1,         # up to 10% shift in height/width\n",
    "    max_rotation=0.05            # ~±5% of 2π (~±9°)\n",
    "):\n",
    "    \"\"\"\n",
    "    Randomly augments an image and adjusts steering angle accordingly.\n",
    "    \n",
    "    Args:\n",
    "        image: 3D tf.Tensor [H, W, C], dtype uint8 or float32.\n",
    "        steering_angle: float scalar (Python float or 0-D tf.Tensor).\n",
    "        *_prob: probability of applying each augmentation (0..1).\n",
    "        max_*: magnitude controls for each operation.\n",
    "    Returns:\n",
    "        aug_image: augmented image, float32 in [0,1], shape [H, W, C]\n",
    "        aug_angle: adjusted steering angle (flipped if image flipped)\n",
    "    \"\"\"\n",
    "    # Ensure float32 in [0,1]\n",
    "    img = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    angle = tf.cast(steering_angle, tf.float32)\n",
    "\n",
    "    H = tf.shape(img)[0]\n",
    "    W = tf.shape(img)[1]\n",
    "    \n",
    " # -------- Flip (horizontal) --------\n",
    "    # If applied, invert steering angle\n",
    "    do_flip = tf.less(tf.random.uniform([]), flip_prob)\n",
    "    img = tf.cond(\n",
    "        do_flip,\n",
    "        lambda: tf.image.flip_left_right(img),\n",
    "        lambda: img\n",
    "    )\n",
    "    angle = tf.cond(do_flip, lambda: -angle, lambda: angle)\n",
    "\n",
    "    # -------- Brightness --------\n",
    "    def brightness(x):\n",
    "        return tf.clip_by_value(\n",
    "            tf.image.random_brightness(x, max_delta=max_brightness_delta),\n",
    "            0.0, 1.0\n",
    "        )\n",
    "    img = tf.cond(tf.less(tf.random.uniform([]), brightness_prob),\n",
    "                  lambda: brightness(img),\n",
    "                  lambda: img)\n",
    "\n",
    "    # -------- Zoom (crop center, then resize back) --------\n",
    "    # Zoom-in only (keeps size by resizing back); simpler & robust\n",
    "    def zoom(x):\n",
    "        zoom_factor = 1.0 - tf.random.uniform([], 0.0, max_zoom)  # e.g., 0.8..1.0\n",
    "        new_h = tf.cast(tf.round(tf.cast(H, tf.float32) * zoom_factor), tf.int32)\n",
    "        new_w = tf.cast(tf.round(tf.cast(W, tf.float32) * zoom_factor), tf.int32)\n",
    "        # center-crop to [new_h, new_w]\n",
    "        offset_h = (H - new_h) // 2\n",
    "        offset_w = (W - new_w) // 2\n",
    "        cropped = tf.image.crop_to_bounding_box(x, offset_h, offset_w, new_h, new_w)\n",
    "        return tf.image.resize(cropped, (H, W), method=\"bilinear\")\n",
    "    img = tf.cond(tf.less(tf.random.uniform([]), zoom_prob),\n",
    "                  lambda: zoom(img),\n",
    "                  lambda: img)\n",
    "\n",
    "    # -------- Pan (translation) --------\n",
    "    # Implemented via pad + random crop to original size\n",
    "    def panning(x):\n",
    "        # pad by up to max_translation * size, then crop a different window\n",
    "        pad_h = tf.cast(tf.round(tf.cast(H, tf.float32) * max_translation), tf.int32)\n",
    "        pad_w = tf.cast(tf.round(tf.cast(W, tf.float32) * max_translation), tf.int32)\n",
    "        padded = tf.pad(x, [[pad_h, pad_h], [pad_w, pad_w], [0, 0]], mode=\"REFLECT\")\n",
    "        # pick a random top-left for crop\n",
    "        max_off_h = 2 * pad_h\n",
    "        max_off_w = 2 * pad_w\n",
    "        off_h = tf.random.uniform([], 0, max_off_h + 1, dtype=tf.int32)\n",
    "        off_w = tf.random.uniform([], 0, max_off_w + 1, dtype=tf.int32)\n",
    "        return tf.image.crop_to_bounding_box(padded, off_h, off_w, H, W)\n",
    "    img = tf.cond(tf.less(tf.random.uniform([]), pan_prob),\n",
    "                  lambda: panning(img),\n",
    "                  lambda: img)\n",
    "\n",
    "    # -------- Rotation --------\n",
    "    # Use Keras preprocessing for rotation (works per-sample)\n",
    "    def rotate(x):\n",
    "        layer = tf.keras.layers.RandomRotation(factor=max_rotation)\n",
    "        # layer expects a batch; set training=True to ensure effect\n",
    "        x = layer(tf.expand_dims(x, 0), training=True)\n",
    "        return tf.squeeze(x, 0)\n",
    "    img = tf.cond(tf.less(tf.random.uniform([]), rotate_prob),\n",
    "                  lambda: rotate(img),\n",
    "                  lambda: img)\n",
    "\n",
    "    return img, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a5317",
   "metadata": {},
   "source": [
    "### Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_bgr):\n",
    "    \n",
    "    # Crop the image to get the road\n",
    "    cropped = img_bgr[60:136, :, :]\n",
    "    \n",
    "    # Convert BGR to YUV\n",
    "    yuv = cv2.cvtColor(cropped, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # Gaussian blur\n",
    "    yuv = cv2.GaussianBlur(yuv, (3, 3), 0)\n",
    "\n",
    "    # Resize\n",
    "    resized = cv2.resize(yuv, (200, 66), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Normalize pixel values to range[0,1]\n",
    "    processed = resized.astype(np.float32) / 255.0\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541eb92",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69920a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
